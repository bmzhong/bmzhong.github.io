### 19. DeepAtlas: Joint Semi-supervised Learning of Image Registration and Segmentation (2019 MICCAI)

1. 动机

   ​        图像分割和配准可以相互促进，配准为分割提供了数据增强，分割为配准提供了额外的监督信息并用于评估配准结果。传统的联合分割和配准的方法对单个图像对进行操作而不是图像的总体，并且计算代价高。此外，获得 3D 医学图像的分割标签是困难的和劳动密集型的。因此，大部分 3D 图像数据都没有标签用于有监督学习。针对这样的情况，作者提出了 DeepAtlas，联合学习深度网络进行弱监督配准和半监督分割，贡献如下：

   - 第一个提出了联合学习两个深度神经网络进行图像配准和分割。DeepAtlas 既可以联合训练，也可以单独训练和预测。
   - DeepAtlas 只需要少量的人工分割标签，使用结构相似性损失来相互指导分割和配准。
   - 在极端情况下，如果只有一个手动分割的图像可用，DeepAtlas 有助于 one-shot 分割，同时提高配准性能。

2. 方法

   ![19_1](images/markdown/19_1.png)

   

   ​        弱监督配准学习（蓝色实线部分）：图像相似性损失$L_i$ , 正则化损失$L_r$ 和解剖相似性损失（即分割标签的Dice损失）$L_a$的加权相加来训练配准网络。

   ​		半监督分割学习（黄色虚线部分）：有监督分割损失$L_{sp}$和解剖相似性损失（通过配准网络扭曲的$I_m$的分割标签和$I_f$的分割标签的Dice损失）$L_a$的加权相加来训练分割网络，损失函数定义如下：
   $$
   L_{seg}=\left \{ \begin{matrix} \lambda_aL_a(S_m\circ\Phi^{-1},F_S(I_t))+\lambda_{sp} L_{sp}(F_S(I_m),S_m),&&&if\ I_t\  is\ unlabeled\ ;  \\ \lambda_aL_a(F_S(I_m)\circ\Phi^{-1},S_t)+\lambda_{sp} L_{sp}(F_S(I_t),S_t),&&&if\ I_m\  is\ unlabeled\ ;\\ \lambda_aL_a(S_m\circ\Phi^{-1},S_t)+\lambda_{sp} L_{sp}(F_S(I_m),S_m),&&&if\ I_t\ and\ I_t \ are\ labeled\ ; \\ 0\ , if\ both\ I_t\ and \ I_m\ are\ unlabeled \ . \end{matrix}\right. \tag{1}
   $$
   当$I_t$没有手动分割标签时，$L_a$相当于有监督分割损失，其中$S_m\circ\Phi^{-1}$是噪声标签。当$I_m$没有手动分割标签时，通过分割网络获得标签，然后扭曲这个标签并与$S_t$计算Dice损失。当$I_t$和$I_m$都有标签时，$L_a$不监督分割网络，因为此时$L_a$中没有$F_s$，但会监督配准网络。当$I_t$和$I_m$都没有标签时，不训练分割网络。总的来说，$I_m$和$I_t$谁没有手动分割标签，谁就通过分割网络来生成伪标签然后用于半监督训练，最少也要有一个手动分割标签。

   ​         训练时，交替训练两个网络中的一个，同时保持另一个固定。由于分割网络收敛更快，分割和配准网络交替训练步数为 1 : 20。由于从零开始联合训练是很困难的，所以作者首先分别对单个分割、配准网络进行预训练。当真实标签数量极少时，比如只有一个，那么从零开始单独训练分割网络是很难的，所以作者最先使用无监督预训练好配准网络，然后再使用这个配准网络从头训练分割网络。直到分割网络能得到合理的结果后，才开始联合训练（交替训练）。

3. 总结

   ​        作者提出了 DeepAtlas 框架，用于仅使用少量标注图像的分割和配准网络的联合学习。当只给出一个真实分割标签时，作者的方法提供了 one-shot 分割学习，大大提高了配准效果。这表明，一个网络可以受益于对另一个网络提供的无标签数据的不完善监督。DeepAtlas 为训练分割和配准网络时缺少真实分割标签提供了一个通用的解决方案。对于未来的工作，为分割和配准网络引入不确定性措施可能有助于缓解一个网络的不良预测对另一个网络的影响。研究通过层共享的分割和注册网络的多任务学习也将是有益的。这可能会进一步提高性能并减小模型尺寸。

4. 问题

   ​         在实验部分，作者考虑 one-shot 的情况（N = 1，N表示手动分割标签的数量），设计了 Semi-DeepAtlas（Semi-DA）：固定无监督（N = 0）预训练好的配准模型，用于从零训练分割网络（N = 1）。使用Semi-DA分割网络和无监督配准网络初始化DA模型。似乎N=1的时候不足以训练好一个分割网络？没有理解它的one-shot分割过程。

   

### 20. A Cross-Stitch Architecture for Joint Registration and Segmentation in Adaptive Radiotherapy （2020 PMLR）

1. 动机

   ​        医学图像自动轮廓化的两种常用方法是图像分割和基于配准的轮廓传播。在自适应图像引导放射治疗的背景下，基于配准的方法具有使用患者解剖结构的先验知识的优势，并且能够准确deform低对比度结构，这些结构难以用附近高对比度结构进行识别。图像分割有其自身的优势，最显著的是能够准确地勾画出器官的轮廓，这些器官在两次访问之间的形状变化很大。

   ​        为了充分利用这两种方法的独特优势，提出了联合配准与分割（JRS）方法。在这项工作中，作者使用多任务学习领域的概念，通过在架构级合并这两个任务来进一步连接配准和分割，而不仅仅是通过损失函数。

2. 方法

   ![20_1](images/markdown/20_1.png)

   ​       

   ​       作者提出的方法如上图所示。JRS输入固定图像$I_f$，移动图像$I_m$，和$I_m$的分割标签$S_m$。 JRS输出$S_f^{pred}$，并与真实标签$S_f$计算Dice loss；输出形变场$\Phi^{pred}$，并计算它的Bending Energy（$\Phi^{pred}$的二阶导数，即Hessian矩阵）作为正则化loss；用$\Phi^{pred}$扭曲$I_m$得到$I_m^{warped}$, 并与$I_f$计算NCC loss；用$\Phi^{pred}$扭曲$S_m$得到$S_m^{warped}$, 并与$S_f$计算NCC loss，这几部分loss加权相加作为总的loss。图中S表示分割层（一个或多个卷积组成的模块），R表示配准层。Cross-Stitch单元是这些层交换信息的模块[1]。Cross-Stitch的计算过程如下：给定分割网络S第$l$层的第$k$个卷积核得到的特征图$X_S^{l,k}$，配准网络R第$l$层的第$k$个卷积核得到的特征图$X_R^{l,k}$，和四个可学习的参数$\alpha_{SS}^{l,k},\alpha_{SR}^{l,k},\alpha_{RS}^{l,k}$和$\alpha_{RR}^{l,k}$，Cross-Stitch单元计算得到的特征图为：
   $$
   \left[
    \begin{matrix}
   	\hat{X}_S^{l,k}\\
   	\hat{X}_R^{l,k}
     \end{matrix}
     \right]=\left[
    \begin{matrix}
   	\alpha_{SS}^{l,k},\alpha_{SR}^{l,k}\\
   	\alpha_{RS}^{l,k},\alpha_{RR}^{l,k}
     \end{matrix}
     \right]\left[
    \begin{matrix}
   	X_S^{l,k}\\
   	X_R^{l,k}
     \end{matrix}
     \right] \tag{1}
   $$
   Cross-Stitch的优点是能够学习在任务之间强烈共享特征映射，如果这是有益的。相反，如果特征映射对完全独立更好，网络可以学习单位矩阵来分离这些特征映射。这允许以一种灵活的方式在两个路径之间共享表示，在参数数量方面的成本可以忽略不计。

   

   [1] Misra I, Shrivastava A, Gupta A, et al. Cross-stitch networks for multi-task learning[C]//Proceedings of the IEEE conference on Computer Vision and Pattern Recognition (CVPR). 2016: 3994-4003

3. 总结

   ​       在这项工作中，作者提出了从架构上连接图像配准和分割，以生成对自适应图像引导放疗至关重要的日常器官勾画。作者尝试了在三维全卷积神经网络中交织配准和分割的不同方法，发现用Cross-Stitch单元连接任务效果最好。通过Cross-Stitch单元，网络学习在其配准路径和分割路径之间交换信息。未来研究的一个有希望的方向是研究在联合网络中添加第三个任务，特别是放射治疗计划的生成。这可能使联合网络产生具有良好剂量学的特征。进一步的研究可能是针对不同患者群体和扫描仪的网络泛化。

4. 问题

   无

### 21. A Hybrid Deep Learning Framework for Integrated Segmentation and Registration: Evaluation on Longitudinal White Matter Tract Changes (2019 MICCAI)

1. 动机

   ​       在纵向成像研究中，可以使用针对纵向数据定制的方法来提高分割的一致性。现有的解决方案通常涉及独立的配准和分割组件，这些组件在多级管道中按顺序或迭代地执行。利用可变形配准建立的空间对应关系，既可用来引入先验值在后续时间点进行分割，也可用来在公共空间中进行分割。作者在这里提出了一种新的混合卷积神经网络，它可以在单一过程中优化分割和配准。

2. 方法

   ![21_1](images/markdown/21_1.png)

   ​         配准和分割共用一个网络。Hybrid CNN为U-Net。

3. 总结

   无

4. 问题

   无

### 22. A segmentation-informed deep learning framework to register dynamic two-dimensional magnetic resonance images of the vocal tract during speech (2022 BSPC)

1. 动机

   ​        动态磁共振(MR)成像可以在讲话过程中可视化发音器。在声道的二维MR图像中量化发音器运动的兴趣越来越大，以更好地理解语音产生，并可能为患者的管理决策提供信息。一些研究使用传统的变形配准方法来估计语音过程中声道的一系列动态2D MR图像中图像之间的位移场，然而，这些研究都没有评估或讨论配准方法是否捕捉到了舌头和软腭接触的变化。这项工作包括两个贡献。首先，它提出了基于分割的深度学习的可变形配准框架，以优化其在语音过程中估计声道动态2D MR图像之间的位移场。其次，这项工作首次使用了基于关节运动（腭咽闭合）的可量化和临床相关方面的度量来评估这些位移场的准确性。

2. 方法

   ![22_1](images/markdown/22_1.png)

   ​        首先，图像对被用作分割网络的输入，分割网络估计图像中六个不同解剖特征的分割。其次，对分割进行后处理，以去除解剖学上不可能的区域（论文中没有细讲）。第三，将图像对和后处理分割用作配准网络的输入，该配准CNN估计位移场以使运动图像与固定图像对齐。第四，将运动图像和位移场作为空间变换器的输入，对运动图像进行变换。在训练和评估过程中，还使用空间变换器对运动图像的ground-truth (GT)分割进行变换。损失函数包括移动图像和固定图像的相似度损失、形变场正则化损失和分割标签的Dice损失。

3. 总结

   ​         作者开发了一种用于估计语音过程中声道动态2D MR图像之间位移场的框架，并发现该框架比目前五种最先进的可变形配准方法和框架更准确地捕捉发音器运动的各个方面。该框架是朝着这类图像系列中关节运动的全自动量化的最终目标迈出的一步。此外，提出了一种基于发音器运动的临床相关和可量化方面的度量标准，并表明这对于评估语音动态MRI图像的注册框架是有用的。

4. 问题

   无

### 23. Deep Complementary Joint Model for Complex Scene Registration and Few-Shot Segmentation on Medical Images (2020 ECCV)

1. 动机

   ![23_1](images/markdown/23_1.png)

   ​        配准与分割任务具有很强的互补性，在复杂场景和few shot情况下可以相互促进。如上图所示，配准模型在训练过程中为分割模型提供了不同的增强数据（扭曲的图像和标签）或弱监督数据（固定图像和扭曲的标签），从而减少了标签的要求，增强了few shot情况下的分割泛化能力。分割模型对区域约束进行反馈，从而在复杂场景中更加关注感兴趣区域（ROI），实现更精细的配准。**上图中的label应该是移动图像的label，此论文中固定图像应该没有ground true label。**

   ​        然而，由于以下原因，这种互补拓扑的进一步利用受到阻碍：

   - Limitation 1：数据增强能力下降（上图（a））。配准模型在训练过程中，学习匹配真实情况的变形规则，生成不同的扭曲图像作为增强数据，提高分割泛化能力。然而，扭曲图像与固定图像之间的相似度增加并趋于稳定，随着相似度的稳定，扭曲图像的多样性逐渐减少。因此，在配准网络的后期训练阶段，在不同的epoch生成相同的扭曲图像，导致增强数据多样性降低。因此配准模型的数据增强能力下降，限制了分割的进一步增强。
   - Limitation 2：弱监督数据中的错位区域（上图（b））。弱监督数据扩大了标记数据集，并为分割模型提供了额外的监督信息。但是，这些数据中较大的错位区域会产生不正确的优化目标，如果直接使用会扰乱训练过程，导致严重的误分割。
   - Limitation 3：缺乏基于标签的区域约束（上图（c））。然而，在few-shot环境下，由于标签较少，缺乏基于标签的区域约束。因此在复杂场景下，配准模型会进行粗糙优化，复杂的背景会限制在ROI上的配准性能。

   ​       针对这三个问题，作者提出了三个解决方案（第2节叙述）。本文提出了一种深度互补联合模型（Deep Complementary Joint Model, DeepRS），该模型最小化复杂场景下的背景干扰，以实现对ROI的更精细配准，并大大降低了少镜头情况下分割的标签要求，以获得更高的泛化能力。

2. 方法

   ![23_2](images/markdown/23_2.png)

   Solution 1: Deep Structure Sampling (DSS) for Sustainable Data Augmentation. 

   ![23_3](images/markdown/23_3.png)

   ​        DSS块通过在变形场中嵌入随机扰动因子，持续生成不同的增强数据，以增加扭曲图像和标签的不确定性。配准过程是图像结构信息的位移，而形变程度的扰动实现了对该位移路径上的信息采样。因此，DSS块带来两个优势：1）可持续的数据增强。通过扰动因子控制配准网络的变形程度，保证配准网络能够持续生成多样化的增强数据。2）真实分布。从位移路径中提取结构信息，得到的增强数据比其他人工增强方法更符合实际分布。上图 a）对形变场$\phi$乘以从均匀分布中采样得到的扰动因子$\alpha$, 得到采样后的形变场$\hat{\phi}$。因此，即使配准网络已经融合，被它扭曲的图像和变形的标签仍然会有很大的多样性。从图 b）可以看出，随着α的增大，由于其结构信息接近于固定图像，扭曲图像逐渐接近于固定图像。

   Solution 2: Alignment Confidence Map (ACM) for Supervision Information Utilization.

   ​       基于Patch-GAN的像素级鉴别器学习扭曲图像和固定图像之间的相似性，并输出突出显示对齐区域的对齐置信度图。因此，在计算弱监督损失函数时，通过这些对齐置信度图可以抑制不对齐的区域，并利用对齐区域中的监督信息进行更高的分割泛化，如式（1）所示
   $$
   L_{acm}=-D(W(x_m,\hat{\phi}))\ W(y_m,\hat{\phi})\ logS(x_f) \tag{1}
   $$
   其中，$x_m,y_m,x_f$和$\hat{\phi}$ 分别表示移动图像、移动图像的标签、固定图像和采样的形变场。 $D(\cdot,\cdot)$表示计算两个图像直接的相似度，$W(\cdot,\cdot)$表示扭曲操作。$D(\cdot,\cdot)$计算得到的应该还是一个矩阵，表示对应位置的像素的相似度。$S(x_f)$应该是分割网络输出的软分类标签。$W(y_m,\hat{\phi})和$$S(x_f)$重合（对齐）的区域权重大，对应的相似度损失就越大，误差区域的损失值将得到较低的权重，从而抑制干扰。由于$y_m$是0,1二值化的，不重合的部分权重应该是为0。**这个公式中似乎没有对齐置信度图，即图中的绿色箭头。而且，Limitation 2说的应该是固定图像和扭曲得到的标签的不对齐问题，但这里解决的是输入到配准网络的扭曲标签和分割后的标签不对齐的问题？**

   Solution 3:  Deep-Based Region Constraint (DRC) for Finer Registration on ROIs.

   ​        DRC策略通过来自分割网络的固定和扭曲分割掩码之间的约束（公式（2））来引导注意力在ROI上进行更精细的配准。该深度区域约束以变形图像和固定图像中对应区域的对齐为优化目标，实现了 1）在少镜头情况下释放基于标签的区域约束的标签要求，2）独立优化不同区域以避免相互之间的不对齐，3）在ROI上额外关注区域以实现更精细的配准。
   $$
   L_{drc}=-(S(W(x_m,\hat{\phi}))-S(x_f))^2 \tag{2}
   $$
   即分别在分割网络中输入扭曲的固定图像和固定图像，输出两个分割图像，计算它们的MSE。每个ROI在不同通道中计算，得到独立的精细优化，**而任务不相关区域在一个后台通道中计算（不理解）**。因此，ROI上的精细配准是可用的，并避免了区域间的错误配准。

   ​       DeepRS模型中的配准网络、分割网络和像素级鉴别器通过不同的损失函数组合进行训练，以协调训练过程，实现相互改进。配准网络的损失函数为：
   $$
   L_{reg}=\lambda_{adv}L_{adv}+\lambda_{drc}L_{drc}+\lambda_{cc}L_{cc}+\lambda_RL_{R}
   $$
   其中，像素级鉴别器的对抗损失$L_{adv}$提供了扭曲图像和固定图像之间的相似度度量，分割网络中DRC的损失引起了对ROI的配准关注，$L_{cc}$表示局部互相关损失，$L_R$表示形变场的正则化损失。分割网络的损失函数$L_{seg}$由两部分组成：
   $$
   L_{seg}=\lambda_{acm}L_{acm}+\lambda_{ce}L_{ce}
   $$
   ACM损失$L_{acm}$将弱监督数据加入到训练中，以获得更高的分割泛化能力，扭曲标签和扭曲图像通过分割网络得到的标签之间的交叉熵损失$L_{ce}$来保持正确的优化目标。鉴别器由参考图像$x_r$和固定图像$x_f$组成的配准图像对作为阳性情况，由扭曲图像$x_w$和固定图像$x_f$组成的图像对作为阴性情况。参考图像$x_r$是运动图像$x_m$和固定图像$x_f$的融合，$x_r=\beta*x_m+(1-\beta*x_f)$。鉴别器的损失除了$L_{adv}$外，还有鉴别真假固定图像的损失$L_D$
   $$
   L_D=-log(D(x_r,x_f))-log(1-D(x_w,x_f))
   $$

3. 总结

   ​       本文提出了一种用于复杂场景配准和少镜头分割的深度互补联合模型（DeepRS）。本文提出的DSS块通过扰动因子随机调整变形场，从而提高了扭曲图像和标签的活性，实现了可持续的数据增强能力；提出的ACM方法通过像素级鉴别器的对齐置信度映射有效地利用弱监督数据中的监督信息，带来更高的分割泛化；提出的DRC策略从分割模型中构建了扭曲和固定图像之间的无标签损失，从而在ROI上实现更精细的配准。本文的工作大大降低了对大型标记数据集的要求，并提供了精细的优化目标，从而提高了配准和分割精度，大大节省了成本。特别是，我们的DeepRS模型在一些标记困难、场景复杂或数据集小的情况下具有很大的潜力。

4. 问题

   第2节加粗部分。

### 24. Deep Learning-Based Concurrent Brain Registration and Tumor Segmentation (2019 Frontiers in Computational Neuroscience)

1. 方法

   ​        本文中，我们提出了一种基于双重深度学习的架构，同时解决配准和肿瘤分割问题，放松了预测肿瘤区域内的配准约束，同时提供位移场和分割图像。

   ![24_1](images/markdown/24_1.png)

​                 共享编码器，分离解码器结构。

### 25. Image-and-Spatial Transformer Networks for Structure-Guided Image Registration (2019 MICCAI)

1. 动机

   ​        作者认为到目前为止，基于神经网络的图像配准并没有充分利用深度表示学习。同时观察到，无论监督方法还是无监督方法都没有利用神经网络的两个关键优势，即 1）学习为下游任务优化的新表示的能力，以及 2）在训练期间incorporate额外的信息并从中受益的能力，但是这些信息在测试时不可用或很难获得。这种额外的监督（如分割标签和landmark等）可以帮助在测试时以不同于单独使用图像强度的方式指导配准。例如，配准可能专注于特定的Structures-of-Interest (SoI)。然而，目前的方法不能保留或显式提取这些额外的信息，因此不能在测试时进一步使用。

   ​        为了克服这些限制，并充分利用神经网络学习表示的关键能力，引入了图像和空间转换网络（ISTN），其中添加了专用的图像转换网络（ITN）到空间转换网络（STN）的头部，旨在提取和保留有关SoI的信息。ITN产生一种新的图像表示，该图像表示以端到端方式学习，并针对下游配准任务进行优化。这不仅允许我们在测试时预测良好的初始转换，而且允许使用完全相同的模型进行精确的特定于测试的迭代细化，从而实现结构引导配准。

2. 方法

   ​        STN是大多数基于DL的图像配准网络的构建块。STN有两个主要组成部分：使用卷积层学习输入的新表示的特征提取部分，以及将这些表示映射到转换参数的第二部分。然而，STN可以学习的表示形式并不是公开的，而是在推理过程中保持隐藏（可能是指无法直观理解到这些表示的所代表的含义）。作者通过引入专用的图像转换网络，重新设计了基于图像配准的神经网络转换模块的基本构建模块。

   ![25_1](images/markdown/25_1.png)

   

   ​      作者将ITN定义为卷积神经网络，将输入图像映射到与$S_M$和$S_F$有相同大小和维度的输出图像$M'$和$F'$。$S_M$和$S_F$分别是固定图像和移动图像的监督信息（如分割图像或landmark等）。然后将$M'$和$F'$输入到STN网络中，输出变换参数$\theta$。图中虚线框里面有两幅图像，$F$, $M$和$S$分别表示固定图像、移动图像和监督图像，下标$\theta$表示对图像进行变换，$L$表示对应两幅图像的相似性损失。有explict和implicit两个损失组合策略，对应的损失项如上图所示。总的来说ITN的作用就是将输入图像变成相应的监督图像，如果监督信息是分割图像，那么ITN就是分割网络，如下图所示，第一行逐渐输出分割标签，第二行逐渐输出landmark。

   ![25_2](images/markdown/25_2.png)

3. 总结

   ​       ISTN是一种基于神经网络的结构引导图像配准的通用框架，使用学习表示进行特定测试的细化。在SoI信息包含噪声的情况下，隐式学习表示可能有助于防止过拟合。

4. 问题

   ​       作者说ITN的作用是显式地公开学习的图像表示，这对于STN解决的下游配准任务是最优的。但我感觉输入的$M'$和$F'$只包含有监督的那部分信息，似乎不足以产生能够对原始图像进行良好变换的参数。